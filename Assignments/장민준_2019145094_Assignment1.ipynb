{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"장민준_2019145094_Assignment1.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5ydlTMIPwyS4"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn.datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8cHqEAbSwyij"},"source":["## Assignment 1-1\n","동영상 데이터에 대한 Linear classifier를 구현해보세요\n","\n","- Input data : 32 x 32 size, RGB channel, 100 frame\n","- the number of samples : 500\n","\n","**Input data, weights, bias, score 가 출력될 수 있도록 구현해주세요**"]},{"cell_type":"code","metadata":{"id":"N4NH1kKzwyWG"},"source":["# Assignment 1-1 구현은 여기서\n","\n","# parameter setting\n","num_class = 10\n","num_sample = 500  # 500 sample case\n","mov_shape = [32, 32, 3, 100, num_sample]  # img row 32 x img column 32 x img channel 3 x frame 100 x num sample\n","mov_size = mov_shape[0]*mov_shape[1]*mov_shape[2]*mov_shape[3] # 307200\n","\n","x_movie = np.random.randint(255, size = mov_shape) # Input (size 32 x 32 x 3 x 100)\n","\n","# linear model\n","\n","x = np.reshape(x_movie, (-1, num_sample)) # Input (size 307200 x 500) --> (image_size x sample)\n","W = np.random.normal(0, 1, size = (num_class, mov_size)) # Weights (size 10 x 307200) , 0~1 사이 normalize된 Weight값 생성\n","b = np.random.normal(0, 1, size = (num_class, num_sample)) # bias (size 10 x 500) , 0~1 사이 normalize된 bias값 생성\n","\n","s = np.dot(W, x) + b # Score (size 10 x 500)\n","\n","print('input data size : ',x.shape)\n","print('input data is : ',x)\n","print()\n","print('weight size : ', W.shape)\n","print('weight is : ', W)\n","print()\n","print('bias size : ', b.shape)\n","print('bias is : ', b)\n","print()\n","print('score size : ',s.shape)\n","print('score is : ',s)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dcpZnrdYwwTe"},"source":["##Assignment 1-2\n","\n","1) L2 Regularization을 구현해보세요 (아래 Loss_reg 함수 참조)\n","\n","- 코드만 구현하면 됩니다\n","\n","\n","2) 주어진 MNIST dataset을 이용하여 SVM loss와 Regularization loss를 구해보세요\n","\n","- SVM loss와 L1, L2 Regularization loss를 모두 출력해 주세요\n","\n","3) Total loss 구해보세요 (lambda = 0.1)\n","\n","- lambda값을 0.1로 설정하여 total loss를 모두 출력해주세요"]},{"cell_type":"code","metadata":{"id":"0Fvjs18bzE61"},"source":["# SVM Loss \n","\n","def Loss_SVM(s, y):\n","    delta = 1.0\n","    [num_class, num_sample] = s.shape\n","    Li = 0\n","    for i in range(num_sample):\n","        ysample = y[:,i]\n","        ssample = s[:,i]\n","        ysample_index = np.where(ysample==1)[0][0]\n","        for j in range(num_class):\n","            if j == ysample_index:\n","                continue\n","            else:\n","                Li += max(0, ssample[j] - ssample[ysample_index] + delta)\n","    return Li / num_sample"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUUWkSp1yoMB"},"source":["# mnist data load\n","\n","mnist = sklearn.datasets.fetch_openml('mnist_784', data_home=\"mnist_784\")\n","\n","num_sample = 5000\n","num_class = 10\n","\n","# mnist dataset은 원해 28 x 28 이미지이다.\n","x = mnist.data[:num_sample] #x[i]는 1차원 배열, x는 1x784가 5000개 들어있는 2차원 배열, 0~255까지 흑백 이미지 데이터\n","img_size = x[0].size #784\n","# plt.imshow(x[0].reshape(28,28))\n","y_index = mnist.target[:num_sample]\n","\n","y = np.zeros((num_class, num_sample))\n","for idx in range(num_sample):\n","    y[int(y_index[idx]), idx] = 1    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQt-dvUax0kZ"},"source":["# 1) Loss reg 구현은 여기서\n","\n","def Loss_reg(W, dim=2):\n","    if dim == 1: # L1 regularization:\n","        reg = np.sum(abs(W))\n","    elif dim == 2:\n","        \n","        W2 = np.sqrt(W) #L2 regularization을 위해 Weight의 각 요소를 제곱한다.\n","        W2[np.isnan(W2)]=0 # 수가 너무 작아 nan이 발생하는 부분을 0으로 치환한다.\n","        reg = np.sum(W2) #제곱의 합\n","\n","    return reg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xanQJJox-G-"},"source":["# 2) MNIST linear classifer 구현은 여기서\n","x = np.reshape(x, (-1, num_sample)) # 784 x 5000\n","W = np.random.normal(0, 1, size = (num_class, img_size)) # 10 x s784\n","b = np.random.normal(0, 1, size = (num_class, num_sample)) # 10 x 5000\n","\n","s = np.dot(W, x) + b # 10 x 5000\n","print(x.shape)\n","print(W.shape)\n","print(b.shape)\n","print(s.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWLiXJpHyE0_"},"source":["# 3) Total Loss 구현은 여기서\n","Lambda = 0.1 # regularization rate Lambda == 0.1\n","SVM_L = Loss_SVM(s,y) # loss값\n","L1_L = Loss_reg(W,1)\n","L2_L = Loss_reg(W,2)\n","\n","# Loss function = Loss + lambda x regularization_term\n","Total_L1 = SVM_L + Lambda*L1_L # L1 regularization이 적용된 totla loss\n","Total_L2 = SVM_L + Lambda*L2_L # L2 regularization이 적용된 totla loss\n","\n","print(\"Total Loss is as below\")\n","print(\"Loss + lambda*L1_reg : \", Total_L1) # L1 regularization이 적용된 totla loss 출력\n","print(\"Loss + lambda*L2_reg : \", Total_L2) # L2 regularization이 적용된 totla loss 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWb8bJIq-l_t"},"source":[""],"execution_count":null,"outputs":[]}]}