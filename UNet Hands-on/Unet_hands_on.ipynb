{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unet_hands_on.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xGen06RyWo6X","executionInfo":{"status":"ok","timestamp":1638878461660,"user_tz":-540,"elapsed":6261,"user":{"displayName":"‍장민준(학부학생/공과대학 기계공학)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438421046769211824"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms.functional as TF\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNET(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],):\n","        super(UNET, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down part of UNET\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up part of UNET\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(\n","                    feature*2, feature, kernel_size=2, stride=2,\n","                )\n","            )\n","            self.ups.append(DoubleConv(feature*2, feature))\n","\n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","\n","        for idx in range(0, len(self.ups), 2): \n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx//2] \n","\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx+1](concat_skip) \n","\n","        return self.final_conv(x)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibaWVsiDccNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638878492763,"user_tz":-540,"elapsed":17338,"user":{"displayName":"‍장민준(학부학생/공과대학 기계공학)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438421046769211824"}},"outputId":"c488a058-40c7-40ce-c185-4a730ea7211d"},"source":["# google drive를 mount 시키기 (데이터셋 연동을 위함)\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"jHLEMfauiQju","executionInfo":{"status":"ok","timestamp":1638878493162,"user_tz":-540,"elapsed":401,"user":{"displayName":"‍장민준(학부학생/공과대학 기계공학)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438421046769211824"}}},"source":["import os\n","os.chdir('/content/drive/MyDrive/IntroToAI/UNet Hands-on/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYnQ6CH2dMPq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638878499037,"user_tz":-540,"elapsed":5877,"user":{"displayName":"‍장민준(학부학생/공과대학 기계공학)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438421046769211824"}},"outputId":"9703f9c3-9657-4109-e80f-461426e68025"},"source":["!pip install albumentations==0.4.6"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting albumentations==0.4.6\n","  Downloading albumentations-0.4.6.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n","Collecting imgaug>=0.4.0\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[K     |████████████████████████████████| 948 kB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=2de46e2c36d1909e68c69f5973d891397fc19efbb0f3bddd5ada3d6e21712638\n","  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n","Successfully built albumentations\n","Installing collected packages: imgaug, albumentations\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"]}]},{"cell_type":"code","metadata":{"id":"rwFO9CgiWXKx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638878638519,"user_tz":-540,"elapsed":35575,"user":{"displayName":"‍장민준(학부학생/공과대학 기계공학)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438421046769211824"}},"outputId":"fce5cf30-13c3-4d24-9668-f29c136d0aec"},"source":["import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","from utils import (\n","    load_checkpoint,\n","    save_checkpoint,\n","    get_loaders,\n","    check_accuracy,\n","    save_predictions_as_imgs,\n",")\n","\n","# Hyperparameters etc.\n","LEARNING_RATE = 1e-4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 3\n","NUM_WORKERS = 2\n","IMAGE_HEIGHT = 160  # 1280 originally\n","IMAGE_WIDTH = 240  # 1918 originally\n","PIN_MEMORY = True\n","LOAD_MODEL = False\n","TRAIN_IMG_DIR = \"data/train_images/\"\n","TRAIN_MASK_DIR = \"data/train_masks/\"\n","VAL_IMG_DIR = \"data/val_images/\"\n","VAL_MASK_DIR = \"data/val_masks/\"\n","\n","def train_fn(loader, model, optimizer, loss_fn, scaler):\n","    loop = tqdm(loader)\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=DEVICE)\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n","\n","        # Forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        # Backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # Update tqdm loop\n","        loop.set_postfix(loss=loss.item())\n","\n","def main():\n","    # Train 시 적용하는 augmentation \n","    train_transform = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Rotate(limit=35, p=1.0),\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.1),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","    # Validation 시 적용하는 augmentation.\n","    val_transforms = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    ## Model 및 loss function, optimizer 정의.\n","    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n","    loss_fn = nn.BCEWithLogitsLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","    ## Data loader 정의.\n","    train_loader, val_loader = get_loaders(\n","        TRAIN_IMG_DIR,\n","        TRAIN_MASK_DIR,\n","        VAL_IMG_DIR,\n","        VAL_MASK_DIR,\n","        BATCH_SIZE,\n","        train_transform,\n","        val_transforms,\n","        NUM_WORKERS,\n","        PIN_MEMORY,\n","    )\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(torch.load(\"my_checkpoint_pretrained.pth.tar\"), model)\n","\n","    check_accuracy(val_loader, model, device=DEVICE)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","\n","        # Save model\n","        checkpoint = {\n","            # Pytorch에서 모델의 state_dict은 학습가능한 매개변수 (weight & bias)가 담겨있는 딕셔너리(Dictionary)입니다. \n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\":optimizer.state_dict(),\n","        }\n","        save_checkpoint(checkpoint)\n","\n","        # Check accuracy\n","        check_accuracy(val_loader, model, device=DEVICE)\n","\n","        # Print some examples to a folder\n","        save_predictions_as_imgs(\n","            val_loader, model, folder=\"saved_images/\", device=DEVICE\n","        )\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 249033/1228800 with acc 20.27\n","Dice score: 0.3364497423171997\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [00:04<00:00,  2.02s/it, loss=0.632]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 249033/1228800 with acc 20.27\n","Dice score: 0.3364497423171997\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [00:04<00:00,  2.02s/it, loss=0.548]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 864172/1228800 with acc 70.33\n","Dice score: 0.1113579049706459\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [00:04<00:00,  2.02s/it, loss=0.493]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 979767/1228800 with acc 79.73\n","Dice score: 0.0\n"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"2W19uvMAEELi"},"source":[""],"execution_count":null,"outputs":[]}]}